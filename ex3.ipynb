{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"Modularity matrix of graphs.\n",
    "\"\"\"\n",
    "#    Copyright (C) 2004-2015 by\n",
    "#    Aric Hagberg <hagberg@lanl.gov>\n",
    "#    Dan Schult <dschult@colgate.edu>\n",
    "#    Pieter Swart <swart@lanl.gov>\n",
    "#    All rights reserved.\n",
    "#    BSD license.\n",
    "from __future__ import division\n",
    "import networkx as nx\n",
    "from networkx.utils import not_implemented_for\n",
    "__author__ = \"\\n\".join(['Aric Hagberg <aric.hagberg@gmail.com>',\n",
    "                        'Pieter Swart (swart@lanl.gov)',\n",
    "                        'Dan Schult (dschult@colgate.edu)',\n",
    "                        'Jean-Gabriel Young (Jean.gabriel.young@gmail.com)'])\n",
    "__all__ = ['modularity_matrix', 'directed_modularity_matrix']\n",
    "\n",
    "\n",
    "def modularity_matrix(G, nodelist=None):\n",
    "\n",
    "    if nodelist is None:\n",
    "        nodelist = G.nodes()\n",
    "    A = nx.to_scipy_sparse_matrix(G, nodelist=nodelist, format='csr')\n",
    "    k = A.sum(axis=1)\n",
    "    m = G.number_of_edges()\n",
    "    # Expected adjacency matrix\n",
    "    X = k * k.transpose() / (2 * m)\n",
    "    return A - X\n",
    ")\n",
    "def directed_modularity_matrix(G, nodelist=None):\n",
    "    if nodelist is None:\n",
    "        nodelist = G.nodes()\n",
    "    A = nx.to_scipy_sparse_matrix(G, nodelist=nodelist, format='csr')\n",
    "    k_in = A.sum(axis=0)\n",
    "    k_out = A.sum(axis=1)\n",
    "    m = G.number_of_edges()\n",
    "    # Expected adjacency matrix\n",
    "    X = k_out * k_in / m\n",
    "    return A - X\n",
    "\n",
    "\"\"\"Functions for computing communities based on centrality notions.\"\"\"\n",
    "\n",
    "def girvan_newman(G, most_valuable_edge=None):\n",
    "\n",
    "    # If the graph is already empty, simply return its connected\n",
    "    # components.\n",
    "    if G.number_of_edges() == 0:\n",
    "        yield tuple(nx.connected_components(G))\n",
    "        return\n",
    "    # If no function is provided for computing the most valuable edge,\n",
    "    # use the edge betweenness centrality.\n",
    "    if most_valuable_edge is None:\n",
    "        def most_valuable_edge(G):\n",
    "            \"\"\"Returns the edge with the highest betweenness centrality\n",
    "            in the graph `G`.\n",
    "\n",
    "            \"\"\"\n",
    "            # We have guaranteed that the graph is non-empty, so this\n",
    "            # dictionary will never be empty.\n",
    "            betweenness = nx.edge_betweenness_centrality(G)\n",
    "            return max(betweenness, key=betweenness.get)\n",
    "    # The copy of G here must include the edge weight data.\n",
    "    g = G.copy().to_undirected()\n",
    "    # Self-loops must be removed because their removal has no effect on\n",
    "    # the connected components of the graph.\n",
    "    g.remove_edges_from(g.selfloop_edges())\n",
    "    while g.number_of_edges() > 0:\n",
    "        yield _without_most_central_edges(g, most_valuable_edge)\n",
    "\n",
    "\n",
    "\n",
    "def _without_most_central_edges(G, most_valuable_edge):\n",
    "    \"\"\"Returns the connected components of the graph that results from\n",
    "    repeatedly removing the most \"valuable\" edge in the graph.\n",
    "\n",
    "    `G` must be a non-empty graph. This function modifies the graph `G`\n",
    "    in-place; that is, it removes edges on the graph `G`.\n",
    "\n",
    "    `most_valuable_edge` is a function that takes the graph `G` as input\n",
    "    (or a subgraph with one or more edges of `G` removed) and returns an\n",
    "    edge. That edge will be removed and this process will be repeated\n",
    "    until the number of connected components in the graph increases.\n",
    "\n",
    "    \"\"\"\n",
    "    original_num_components = nx.number_connected_components(G)\n",
    "    num_new_components = original_num_components\n",
    "    while num_new_components <= original_num_components:\n",
    "        edge = most_valuable_edge(G)\n",
    "        G.remove_edge(*edge)\n",
    "        new_components = tuple(nx.connected_components(G))\n",
    "        num_new_components = len(new_components)\n",
    "    return new_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Political blogs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import gml file, sepparate G1 (websites graph) and G2 (liberal vs conservative graph)\n",
    "pol_blog = '/home/frank/Dropbox/school/Networks/data/pol_blog/polblogs.gml'\n",
    "G1 = nx.read_gml(pol_blog)\n",
    "pos1 = nx.spring_layout(G1)\n",
    "\n",
    "lib_nodes = G1.subgraph( [n for n,d in G1.node.items() if d['value'] == 0])\n",
    "cons_nodes = G1.subgraph( [n for n,d in G1.node.items() if d['value'] == 1])\n",
    "nx.draw_networkx_nodes(lib_nodes, pos1,node_color='r', alpha = 0.3)\n",
    "nx.draw_networkx_nodes(cons_nodes, pos1,node_color='b', alpha = 0.3)\n",
    "nx.draw_networkx_edges(G1, pos1, alpha = 0.3)\n",
    "plt.rcParams[\"figure.figsize\"] = [20,20]\n",
    "plt.title(\"Political blogs network\", alpha = 0.3)\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pol_blog = '/home/frank/Dropbox/school/Networks/data/pol_blog/polblogs.gml'\n",
    "G1 = nx.read_gml(pol_blog)\n",
    "\n",
    "#Run girvan_newman and identify communities\n",
    "comp = girvan_newman(G)\n",
    "groupings = tuple(c for c in next(comp))\n",
    "\n",
    "len(groupings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Girvan Newman methdo has identified 270 communities in this set, with the total of 1490 nodes present(urls). Looking at the previous graph, where we cannot easily identify communities due to large mixture liberal and conservative blogs interconnected. 270 modules is significantly larger number of groupings and should be investigated with additional data about main geographical and demographical features of each website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find largest eigenvalues.\n",
    "\n",
    "import numpy as np\n",
    "#from time import clock\n",
    "from scipy.linalg import eigh as largest_eigh\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh as largest_eigsh\n",
    "\n",
    "#np.set_printoptions(suppress=True)\n",
    "#np.random.seed(0)\n",
    "#N=5000\n",
    "#k=10\n",
    "#X = np.random.random((N,N)) - 0.5\n",
    "#X = np.dot(X, X.T) #create a symmetric matrix\n",
    "\n",
    "# Benchmark the dense routine\n",
    "#start = clock()\n",
    "evals_large, evecs_large = largest_eigh(X, eigvals=(N-k,N-1))\n",
    "#elapsed = (clock() - start)\n",
    "#print \"eigh elapsed time: \", elapsed\n",
    "\n",
    "# Benchmark the sparse routine\n",
    "#start = clock()\n",
    "evals_large_sparse, evecs_large_sparse = largest_eigsh(X, k, which='LM')\n",
    "#elapsed = (clock() - start)\n",
    "#print \"eigsh elapsed time: \", elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_1 = modularity_matrix(G1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file2 = \"/home/frank/Dropbox/school/Networks/data/Social_networks of pos_sentiment/prisoninter_st.txt\"\n",
    "\n",
    "G2_df = np.loadtxt(file2, delimiter=\" \")\n",
    "#columns = ['source','target','weight']\n",
    "\n",
    "source = list(G2_df[:,0])\n",
    "target = list(G2_df[:,1])\n",
    "nodes = set(list(G2_df[:,1]))\n",
    "edges = zip(source,target)\n",
    "\n",
    "G2 = nx.Graph()\n",
    "G2.add_nodes_from(nodes)\n",
    "G2.add_edges_from(edges)\n",
    "\n",
    "nx.draw(G2)\n",
    "plt.title(\"Positive sentiments network\", alpha = 0.3)\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "compw = girvan_newman(G2)\n",
    "groupings2 = tuple(c for c in next(compw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groupings2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to limited number of nodes, resolution limit hasn't been reached and no meaningful information can be obtained from the glande. However, 2 groups have been identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_1 = modularity_matrix(G2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
